{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Duplicate Questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 100 million people visit Quora every month, so it's no surprise that many people ask similar (or the same) questions. Various questions with the same intent can cause people to spend extra time searching for the best answer to their question, and results in members answering multiple versions of the same question. Quora uses random forest to identify duplicated questions to provide a better experience to active seekers and writers, and offer more value to both of these groups in the long term.\n",
    "Follow the steps outlined below to build the appropriate classifier model. \n",
    "\n",
    "\n",
    "Steps:\n",
    "- Download data\n",
    "- Exploration\n",
    "- Cleaning\n",
    "- Feature Engineering\n",
    "- Modeling\n",
    "\n",
    "By the end of this project you should have **a presentation that describes the model you built** and its **performance**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "There is no designated test.csv file. The train.csv file is the entire dataset. Part of the data in the train.csv file should be set aside to act as the final testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exploration and Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"c4ZvyM\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v3.2.0/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"c4ZvyM\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"c4ZvyM\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import lets plot\n",
    "import numpy as np\n",
    "from lets_plot import *\n",
    "LetsPlot.setup_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How big is this dataset?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    255027\n",
       "1    149263\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What portion of our questions are actually duplicate?\n",
    "df['is_duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "   <div id=\"vp1U2n\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"data\":{\n",
       "},\n",
       "\"mapping\":{\n",
       "\"x\":\"is_duplicate\",\n",
       "\"fill\":\"is_duplicate\"\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"ggtitle\":{\n",
       "\"text\":\" \"\n",
       "},\n",
       "\"theme\":{\n",
       "\"name\":\"classic\",\n",
       "\"flavor\":\"high_contrast_dark\"\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[{\n",
       "\"name\":\"Class\",\n",
       "\"aesthetic\":\"x\"\n",
       "},{\n",
       "\"name\":\"Count\",\n",
       "\"aesthetic\":\"y\"\n",
       "},{\n",
       "\"aesthetic\":\"fill\",\n",
       "\"guide\":\"none\",\n",
       "\"discrete\":true\n",
       "}],\n",
       "\"layers\":[{\n",
       "\"geom\":\"bar\",\n",
       "\"mapping\":{\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"data\":{\n",
       "\"..count..\":[255027.0,149263.0],\n",
       "\"is_duplicate\":[0.0,1.0]\n",
       "}\n",
       "}],\n",
       "\"metainfo_list\":[]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"vp1U2n\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ],
      "text/plain": [
       "<lets_plot.plot.core.PlotSpec at 0x313a38160>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot class distribution for each class using ggplot2\n",
    "ggplot(df, aes(x='is_duplicate', fill = 'is_duplicate')) + geom_bar() + ggtitle(\" \") + labs(x=\"Class\", y=\"Count\") +\\\n",
    "scale_fill_discrete(guide='none') + \\\n",
    "theme_classic() + \\\n",
    "flavor_high_contrast_dark() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls in label: 0\n",
      "Number of nulls in text: 1\n",
      "Number of nulls in text: 2\n"
     ]
    }
   ],
   "source": [
    "# Are we missing any data?\n",
    "print('Number of nulls in label: {}'.format(df['is_duplicate'].isnull().sum()))\n",
    "print('Number of nulls in text: {}'.format(df['question1'].isnull().sum()))\n",
    "print('Number of nulls in text: {}'.format(df['question2'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of question pairs for training: 404290\n"
     ]
    }
   ],
   "source": [
    "# How many unique questions are there?\n",
    "print('Total number of question pairs for training: {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many times a question appears in the df\n",
    "qids = pd.Series(df[df['qid1'].notnull()]['qid1'].tolist() + df[df['qid2'].notnull()]['qid2'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "   <div id=\"Jn1rs5\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"data\":{\n",
       "},\n",
       "\"mapping\":{\n",
       "\"x\":\"x\"\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"ggtitle\":{\n",
       "\"text\":\" \"\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[{\n",
       "\"name\":\"Question ID\",\n",
       "\"aesthetic\":\"x\"\n",
       "},{\n",
       "\"name\":\"Count\",\n",
       "\"aesthetic\":\"y\"\n",
       "}],\n",
       "\"layers\":[{\n",
       "\"geom\":\"density\",\n",
       "\"mapping\":{\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"binwidth\":10.0,\n",
       "\"method\":\"histodot\",\n",
       "\"data\":{\n",
       "\"..density..\":[2.1492823508388794E-6,2.3311515735926243E-6,2.5083518806303457E-6,2.6784754540070888E-6,2.839336854995643E-6,2.9890499239927307E-6,3.126086633498013E-6,3.2493159768550513E-6,3.358020535116754E-6,3.4518915970981926E-6,3.531004255301969E-6,3.595776045659485E-6,3.6469130748370917E-6,3.685348161883932E-6,3.7121759786297543E-6,3.7285892725529383E-6,3.7358204211398495E-6,3.735090469255272E-6,3.7275681220184593E-6,3.7143393552880898E-6,3.6963874959339457E-6,3.6745830820776634E-6,3.649682070685421E-6,3.622330819673608E-6,3.5930757916137185E-6,3.562376151540749E-6,3.5306179351364948E-6,3.498127828831717E-6,3.465186151718636E-6,3.432037819786293E-6,3.3989009283878307E-6,3.3659731314595023E-6,3.3334355087134903E-6,3.301454247746231E-6,3.2701809398501784E-6,3.239750956412565E-6,3.2102814727382126E-6,3.1818689720000433E-6,3.154586508271918E-6,3.1284815959200684E-6,3.103574743682197E-6,3.0798588063164822E-6,3.0572994408001145E-6,3.0358367493176903E-6,3.0153878359581107E-6,2.9958502772552016E-6,2.9771068727963666E-6,2.959031281607552E-6,2.9414919365038585E-6,2.9243580739649986E-6,2.9075053169864087E-6,2.8908190634026326E-6,2.874199478825158E-6,2.857563767487338E-6,2.8408480520179616E-6,2.8240083387394847E-6,2.8070206114849644E-6,2.7898795048051386E-6,2.7725964028870733E-6,2.7551976828664543E-6,2.7377218155302516E-6,2.720216129983086E-6,2.702734200044155E-6,2.6853331716229073E-6,2.6680708956608673E-6,2.651003575452782E-6,2.6341839207630274E-6,2.617659809435598E-6,2.6014725456058164E-6,2.5856565712157132E-6,2.570238643245615E-6,2.5552379847672156E-6,2.540666245268486E-6,2.526528225213702E-6,2.512822498015168E-6,2.512822498015168E-6,2.499542394715484E-6,2.486676677883166E-6,2.4742108313789833E-6,2.4621281447287212E-6,2.450410274433089E-6,2.4390380446070073E-6,2.427992014555268E-6,2.41725239573111E-6,2.406799298305458E-6,2.3966126487767807E-6,2.3866715443980403E-6,2.376954366037888E-6,2.3674381922660095E-6,2.358098812089009E-6,2.348910818106669E-6,2.3398476892400797E-6,2.3308824320939662E-6,2.3219881263303012E-6,2.3131387845821636E-6,2.3043101280911077E-6,2.295480473165759E-6,2.286631552593728E-6,2.2777488972071856E-6,2.268822445605075E-6,2.259846662493793E-6,2.2508204428703627E-6,2.241747061018746E-6,2.2326334902611324E-6,2.2234902350678827E-6,2.2143307064631935E-6,2.2051705435197246E-6,2.196027087162313E-6,2.186919152732617E-6,2.177866185711606E-6,2.1688881493972887E-6,2.160004880826989E-6,2.151235698385379E-6,2.142599024940476E-6,2.1341117242435506E-6,2.125788734675707E-6,2.117642369091058E-6,2.1096819202926765E-6,2.1019131110962708E-6,2.0943377599615068E-6,2.0869537887353976E-6,2.0797551454428917E-6,2.0727323245018967E-6,2.0658729692162264E-6,2.0591625964187853E-6,2.0525860183836716E-6,2.046128356433338E-6,2.039776303460615E-6,2.0335196020549414E-6,2.027351873202286E-6,2.0212715094720675E-6,2.0152820836900366E-6,2.0093924726484583E-6,2.0036163721680825E-6,1.9979716582081826E-6,1.992479222670091E-6,1.9871615813850024E-6,1.9820413525065066E-6,1.977139722580483E-6,1.9724749412313215E-6,1.968061088450519E-6,1.9639070764022883E-6,1.960015835041186E-6,1.956384079260903E-6,1.95300239724557E-6,1.9498554711961746E-6,1.9469226269659814E-6,1.9441786756049456E-6,1.9415948451503894E-6,1.9391395472381024E-6,1.9367793112659263E-6,1.9344797677102327E-6,1.932206344310143E-6,1.9299249577757887E-6,1.9276027159568383E-6,1.925208615591845E-6,1.9227140144570404E-6,1.92009334804017E-6,1.917324561747582E-6,1.914389789642805E-6,1.9112757570577743E-6,1.9079743093514586E-6,1.9044827438937097E-6,1.900803860857044E-6,1.8969460204152652E-6,1.8929228367960678E-6,1.88875279129933E-6,1.8844583848183123E-6,1.8800652740883953E-6,1.8756011306189805E-6,1.8710944294411582E-6,1.866573118033846E-6,1.8620634885105229E-6,1.8575888991647059E-6,1.8531689118784482E-6,1.8488185661113012E-6,1.8445478941028626E-6,1.8403618542714297E-6,1.8362605438587235E-6,1.8322395820403565E-6,1.8282908582894557E-6,1.8244033477134214E-6,1.8205641257562426E-6,1.816759179392654E-6,1.8129744868652677E-6,1.8091967037376208E-6,1.8054137467252597E-6,1.8016153874003584E-6,1.7977934493180797E-6,1.7977934493180797E-6,1.7939421035575629E-6,1.7900578049289155E-6,1.7861394159303777E-6,1.7821881376950531E-6,1.7782075365131406E-6,1.7742034797999933E-6,1.7701841022491748E-6,1.766159828577447E-6,1.762143174504579E-6,1.7581485097382666E-6,1.7541916856241863E-6,1.750289519872051E-6,1.7464590619724095E-6,1.7427167630624234E-6,1.7390775451626172E-6,1.7355539732024122E-6,1.7321553457465757E-6,1.7288871254925228E-6,1.7257505692674725E-6,1.7227426177287147E-6,1.7198561589053868E-6,1.717080622522438E-6,1.714402808341842E-6,1.7118079073538443E-6,1.7092806809751713E-6,1.706806464665722E-6,1.7043720881948433E-6,1.701966607582613E-6,1.699581597585944E-6,1.697211235135889E-6,1.6948520631765449E-6,1.692502295307138E-6,1.6901611331922846E-6,1.6878279351937122E-6,1.6855013220499194E-6,1.6831785234606215E-6,1.680854804994683E-6,1.6785233522590124E-6,1.6761752769239304E-6,1.6738000571573263E-6,1.6713861675887537E-6,1.6689219315588432E-6,1.6663965051007672E-6,1.6638008443917544E-6,1.6611285626210968E-6,1.6583767601030876E-6,1.6555464324674596E-6,1.6526427502866778E-6,1.6496749481515336E-6,1.6466559744125997E-6,1.6436018857069201E-6,1.640530963878433E-6,1.6374628135713105E-6,1.6344172890459002E-6,1.6314135013126167E-6,1.6284688758116643E-6,1.6255983322862027E-6,1.6228136714543625E-6,1.6201231980171391E-6,1.6175314737050858E-6,1.6150393463830027E-6,1.612644112937929E-6,1.6103398616244568E-6,1.6081179649774314E-6,1.605967560575857E-6,1.603876155159765E-6,1.6018301737956648E-6,1.599815580426572E-6,1.5978183243938353E-6,1.595824938016587E-6,1.5938228645687346E-6,1.5918009329679744E-6,1.589749536593244E-6,1.5876610170273878E-6,1.5855297219148358E-6,1.5833522356651902E-6,1.5811273305822365E-6,1.5788560019337289E-6,1.576541345692019E-6,1.5741884328222217E-6,1.5718040443695854E-6,1.5693964080055386E-6,1.5669748502549635E-6,1.5645493906292187E-6,1.5621303752086236E-6,1.559728029325003E-6,1.5573520730509071E-6,1.5550113308978146E-6,1.5527134184937882E-6,1.5504644092847665E-6,1.5482687510557796E-6,1.546129076975049E-6,1.5440462271052223E-6,1.542019331019389E-6,1.540045952314938E-6,1.5381223845089264E-6,1.5362438350548506E-6,1.53440482948942E-6,1.5325995082513471E-6,1.5308219492215194E-6,1.5290664679371919E-6,1.5273278496739167E-6,1.5256015432861293E-6,1.5238837293804805E-6,1.5221713952429192E-6,1.520462318052899E-6,1.5187549489989445E-6,1.5170483082320306E-6,1.5153418159079622E-6,1.5136351130350843E-6,1.5119279001287108E-6,1.5102197340197945E-6,1.508509968515476E-6,1.5067975469369886E-6,1.505081069998989E-6,1.5033587137693201E-6,1.5016283433327928E-6,1.499887583473745E-6,1.4981340081863443E-6,1.496365259829679E-6,1.4945792869502444E-6,1.492774541652802E-6,1.4909501534208902E-6,1.4891061026526984E-6,1.4872433363419705E-6,1.4853638659845313E-6,1.4834707660583867E-6,1.4815681198769434E-6,1.4796609292787613E-6,1.4777549323359085E-6,1.475856364893083E-6,1.4739717091184846E-6,1.4721073205947663E-6,1.47026914889671E-6,1.4684623496715503E-6,1.4666910034257206E-6,1.46495778843651E-6,1.4632637739247455E-6,1.461608282573428E-6,1.4599888175286055E-6,1.4584011216019493E-6,1.4568393775260854E-6,1.4552964646966636E-6,1.4537644043443354E-6,1.4522347919991566E-6,1.4522347919991566E-6,1.4506993832179548E-6,1.4491506629891157E-6,1.4475823913159044E-6,1.4459901135084633E-6,1.4443715193233635E-6,1.442726736163438E-6,1.4410583983598534E-6,1.439371541768672E-6,1.4376733069531087E-6,1.4359725383816864E-6,1.4342790854742608E-6,1.4326031856411528E-6,1.4309546405299192E-6,1.4293421266250654E-6,1.427772508981643E-6,1.4262503027192957E-6,1.4247773262474304E-6,1.423352527501451E-6,1.4219720886436085E-6,1.4206296598401367E-6,1.4193168990779439E-6,1.4180240794694178E-6,1.4167408263406858E-6,1.4154569220223022E-6,1.4141630063733099E-6,1.4128513408969574E-6,1.4115162858950718E-6,1.4101546885031685E-6,1.4087660886476568E-6,1.4073526552381676E-6,1.4059190487932936E-6,1.4044719836678285E-6,1.4030197739063528E-6,1.4015717674443635E-6,1.40013771840394E-6,1.3987271958470367E-6,1.3973490286289068E-6,1.3960108515282215E-6,1.394718733472018E-6,1.3934769104921807E-6,1.3922877386445692E-6,1.3911515855426065E-6,1.390066983463458E-6,1.3890307551062116E-6,1.388038269890671E-6,1.387083641885334E-6,1.3861600260231748E-6,1.3852598628866658E-6,1.384375104139943E-6,1.3834973847303275E-6,1.3826182246701167E-6,1.3817291766524326E-6,1.3808219015702483E-6,1.3798883376824592E-6,1.3789208255759037E-6,1.3779122373318914E-6,1.3768561063156472E-6,1.375746860425873E-6,1.374579980049208E-6,1.3733521983237261E-6,1.3720617225116554E-6,1.3707083547054246E-6,1.3692936421872987E-6,1.3678209337637892E-6,1.3662953595866814E-6,1.3647237338089453E-6,1.3631143871628388E-6,1.3614768393979382E-6,1.3598215191778582E-6,1.3581593121387302E-6,1.3565011362947558E-6,1.3548574886823974E-6,1.3532379883469332E-6,1.3516510197110537E-6,1.350103377670493E-6,1.3486000096260355E-6,1.3471439059875082E-6,1.3457360441106894E-6,1.3443754256850496E-6,1.343059238187059E-6,1.3417830927157798E-6,1.3405413168526599E-6,1.3393272965256343E-6,1.3381338058555315E-6,1.3369533964575918E-6,1.3357787150580478E-6,1.3346028140123819E-6,1.3334194112084095E-6,1.3322231259649832E-6,1.3310095941924892E-6,1.329775605707876E-6,1.3285191183660177E-6,1.3272392624725818E-6,1.3259362953484996E-6,1.3246114962122516E-6,1.32326704311809E-6,1.3219058637961307E-6,1.3205314846420943E-6,1.3191478617724444E-6,1.3177592137547863E-6,1.316369886683292E-6,1.3149842055971037E-6,1.3136063643631017E-6,1.3122403347544297E-6,1.3108897988758614E-6,1.309558080701893E-6,1.308248123603568E-6,1.3069624551534256E-6,1.3057031791410916E-6,1.3044719709801435E-6,1.3032700580600276E-6,1.3020982571769807E-6,1.3009569616265125E-6,1.2998461528010415E-6,1.2987654244409991E-6,1.2977140010638717E-6,1.2966907669658778E-6,1.295694273348854E-6,1.2947227832937866E-6,1.29377427180091E-6,1.2928464710151338E-6,1.2919368788506043E-6,1.2910427818208667E-6,1.2901612831267902E-6,1.2892893456168955E-6,1.2884238171719338E-6,1.2875614998781955E-6,1.2866991958704647E-6,1.2858337888797892E-6,1.2849623087779604E-6,1.2840820138090687E-6,1.2831904628287785E-6,1.282285579498728E-6,1.2813656988041299E-6,1.280429425718577E-6,1.2794759363778906E-6,1.2785048516113738E-6,1.2775160703045633E-6,1.2765097485118575E-6,1.2754861800021334E-6,1.2744456292626997E-6,1.2733881486518968E-6,1.2723132978710494E-6,1.271219824421392E-6,1.2701052346513254E-6,1.2689652624742885E-6,1.267793130895833E-6,1.2665786725028996E-6,1.2653071688239457E-6,1.2639579170226912E-6,1.262502519756656E-6,1.26090278079273E-6,1.2591083333277842E-6,1.2570539486973332E-6,1.2546566564516017E-6,1.2518127763054977E-6,1.24839508585661E-6,1.244250333153454E-6,1.2391974356970434E-6,1.2330266979027762E-6,1.2255004054212473E-6,1.2163552000441002E-6,1.2053065054608415E-6,1.192055251363679E-6,1.1762970224661234E-6,1.1577334692108323E-6,1.1360857898835774E-6,1.1111096889876303E-6,1.0826111302601648E-6,1.0504619096156485E-6,1.014614052479971E-6,9.751118388269332E-7,9.321004463524777E-7,8.858302038530943E-7,8.366557909917043E-7,7.850300056640776E-7,7.314920784421102E-7,6.766510165084457E-7,6.211647797574757E-7],\n",
       "\"..quantile..\":[0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,0.75,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\n",
       "\"x\":[1.0,1053.7045009784736,2106.409001956947,3159.113502935421,4211.818003913894,5264.522504892368,6317.227005870842,7369.931506849315,8422.636007827788,9475.340508806263,10528.045009784735,11580.74951076321,12633.454011741684,13686.158512720156,14738.86301369863,15791.567514677103,16844.272015655577,17896.97651663405,18949.681017612525,20002.385518590996,21055.09001956947,22107.794520547945,23160.49902152642,24213.203522504893,25265.908023483367,26318.612524461838,27371.317025440312,28424.021526418786,29476.72602739726,30529.430528375735,31582.135029354205,32634.83953033268,33687.544031311154,34740.248532289625,35792.9530332681,36845.65753424657,37898.36203522505,38951.06653620352,40003.77103718199,41056.47553816047,42109.18003913894,43161.88454011742,44214.58904109589,45267.29354207436,46319.99804305284,47372.70254403131,48425.407045009786,49478.11154598826,50530.816046966735,51583.520547945205,52636.225048923676,53688.929549902154,54741.634050880624,55794.3385518591,56847.04305283757,57899.74755381604,58952.45205479452,60005.15655577299,61057.86105675147,62110.56555772994,63163.27005870841,64215.97455968689,65268.67906066536,66321.38356164383,67374.08806262231,68426.79256360079,69479.49706457925,70532.20156555773,71584.9060665362,72637.61056751468,73690.31506849315,74743.01956947162,75795.7240704501,76848.42857142857,77901.13307240704,77901.13307240704,78953.83757338552,80006.54207436398,81059.24657534246,82111.95107632094,83164.65557729942,84217.36007827788,85270.06457925636,86322.76908023484,87375.4735812133,88428.17808219178,89480.88258317026,90533.58708414872,91586.2915851272,92638.99608610568,93691.70058708415,94744.40508806262,95797.1095890411,96849.81409001957,97902.51859099804,98955.22309197651,100007.92759295499,101060.63209393347,102113.33659491193,103166.04109589041,104218.74559686889,105271.45009784735,106324.15459882583,107376.85909980431,108429.56360078277,109482.26810176125,110534.97260273973,111587.6771037182,112640.38160469667,113693.08610567515,114745.79060665362,115798.49510763209,116851.19960861056,117903.90410958904,118956.6086105675,120009.31311154598,121062.01761252446,122114.72211350294,123167.4266144814,124220.13111545988,125272.83561643836,126325.54011741682,127378.2446183953,128430.94911937378,129483.65362035224,130536.35812133072,131589.0626223092,132641.76712328766,133694.47162426615,134747.17612524462,135799.88062622308,136852.58512720157,137905.28962818003,138957.9941291585,140010.698630137,141063.40313111545,142116.10763209392,143168.8121330724,144221.51663405087,145274.22113502937,146326.92563600783,147379.6301369863,148432.33463796478,149485.03913894325,150537.7436399217,151590.4481409002,152643.15264187867,153695.85714285713,154748.56164383562,155801.2661448141,156853.97064579255,157906.67514677104,158959.3796477495,160012.08414872797,161064.78864970646,162117.49315068492,163170.1976516634,164222.90215264188,165275.60665362034,166328.31115459884,167381.0156555773,168433.72015655576,169486.42465753425,170539.12915851272,171591.83365949118,172644.53816046967,173697.24266144814,174749.9471624266,175802.6516634051,176855.35616438356,177908.06066536202,178960.7651663405,180013.46966731898,181066.17416829744,182118.87866927593,183171.5831702544,184224.2876712329,185276.99217221135,186329.6966731898,187382.4011741683,188435.10567514677,189487.81017612523,190540.51467710373,191593.2191780822,192645.92367906065,193698.62818003914,194751.3326810176,195804.03718199607,196856.74168297456,196856.74168297456,197909.44618395303,198962.1506849315,200014.85518590998,201067.55968688845,202120.26418786694,203172.9686888454,204225.67318982386,205278.37769080236,206331.08219178082,207383.78669275928,208436.49119373778,209489.19569471624,210541.9001956947,211594.6046966732,212647.30919765166,213700.01369863012,214752.71819960861,215805.42270058708,216858.12720156554,217910.83170254403,218963.5362035225,220016.24070450096,221068.94520547945,222121.64970645792,223174.3542074364,224227.05870841487,225279.76320939334,226332.46771037183,227385.1722113503,228437.87671232875,229490.58121330725,230543.2857142857,231595.99021526417,232648.69471624267,233701.39921722113,234754.1037181996,235806.80821917808,236859.51272015655,237912.217221135,238964.9217221135,240017.62622309197,241070.33072407046,242123.03522504892,243175.7397260274,244228.44422700588,245281.14872798434,246333.8532289628,247386.5577299413,248439.26223091976,249491.96673189822,250544.67123287672,251597.37573385518,252650.08023483364,253702.78473581214,254755.4892367906,255808.19373776906,256860.89823874756,257913.60273972602,258966.30724070448,260019.01174168297,261071.71624266144,262124.42074363993,263177.1252446184,264229.82974559686,265282.5342465753,266335.2387475538,267387.9432485323,268440.64774951077,269493.35225048923,270546.0567514677,271598.76125244616,272651.4657534247,273704.17025440314,274756.8747553816,275809.57925636007,276862.28375733853,277914.988258317,278967.6927592955,280020.397260274,281073.10176125244,282125.8062622309,283178.5107632094,284231.21526418783,285283.91976516636,286336.6242661448,287389.3287671233,288442.03326810175,289494.7377690802,290547.44227005873,291600.1467710372,292652.85127201566,293705.5557729941,294758.2602739726,295810.96477495105,296863.66927592957,297916.37377690803,298969.0782778865,300021.78277886496,301074.4872798434,302127.1917808219,303179.8962818004,304232.60078277887,305285.30528375733,306338.0097847358,307390.71428571426,308443.4187866928,309496.12328767125,310548.8277886497,311601.5322896282,312654.23679060664,313706.9412915851,314759.6457925636,315812.3502935421,316865.05479452055,317917.759295499,318970.4637964775,320023.16829745594,321075.87279843446,322128.5772994129,323181.2818003914,324233.98630136985,325286.6908023483,326339.3953033268,327392.0998043053,328444.80430528376,329497.5088062622,330550.2133072407,331602.91780821915,332655.6223091977,333708.32681017614,334761.0313111546,335813.73581213306,336866.4403131115,337919.14481409,338971.8493150685,340024.553816047,341077.25831702544,342129.9628180039,343182.66731898236,344235.3718199608,345288.07632093935,346340.7808219178,347393.4853228963,348446.18982387474,349498.8943248532,349498.8943248532,350551.5988258317,351604.3033268102,352657.00782778865,353709.7123287671,354762.4168297456,355815.12133072404,356867.82583170256,357920.530332681,358973.2348336595,360025.93933463795,361078.6438356164,362131.3483365949,363184.0528375734,364236.75733855186,365289.4618395303,366342.1663405088,367394.87084148725,368447.5753424658,369500.27984344424,370552.9843444227,371605.68884540116,372658.3933463796,373711.0978473581,374763.8023483366,375816.5068493151,376869.21135029354,377921.915851272,378974.62035225047,380027.3248532289,381080.02935420745,382132.7338551859,383185.4383561644,384238.14285714284,385290.8473581213,386343.5518590998,387396.2563600783,388448.96086105675,389501.6653620352,390554.3698630137,391607.07436399214,392659.77886497066,393712.4833659491,394765.1878669276,395817.89236790605,396870.5968688845,397923.301369863,398976.0058708415,400028.71037181997,401081.4148727984,402134.1193737769,403186.82387475536,404239.5283757339,405292.23287671234,406344.9373776908,407397.64187866927,408450.34637964773,409503.0508806262,410555.7553816047,411608.4598825832,412661.16438356164,413713.8688845401,414766.57338551857,415819.27788649703,416871.98238747555,417924.686888454,418977.3913894325,420030.09589041094,421082.8003913894,422135.50489236787,423188.2093933464,424240.91389432485,425293.6183953033,426346.3228962818,427399.02739726024,428451.73189823877,429504.43639921723,430557.1409001957,431609.84540117416,432662.5499021526,433715.2544031311,434767.9589041096,435820.66340508807,436873.36790606653,437926.072407045,438978.77690802346,440031.4814090019,441084.18590998044,442136.8904109589,443189.59491193737,444242.29941291583,445295.0039138943,446347.7084148728,447400.4129158513,448453.11741682974,449505.8219178082,450558.52641878667,451611.23091976513,452663.93542074366,453716.6399217221,454769.3444227006,455822.04892367905,456874.7534246575,457927.457925636,458980.1624266145,460032.86692759296,461085.5714285714,462138.2759295499,463190.98043052835,464243.68493150687,465296.38943248533,466349.0939334638,467401.79843444226,468454.5029354207,469507.2074363992,470559.9119373777,471612.61643835617,472665.32093933463,473718.0254403131,474770.72994129156,475823.43444227,476876.13894324854,477928.843444227,478981.5479452055,480034.25244618393,481086.9569471624,482139.6614481409,483192.3659491194,484245.07045009785,485297.7749510763,486350.4794520548,487403.18395303324,488455.88845401176,489508.5929549902,490561.2974559687,491614.00195694715,492666.7064579256,493719.4109589041,494772.1154598826,495824.81996086106,496877.5244618395,497930.228962818,498982.93346379645,500035.6379647749,501088.34246575343,502141.0469667319,503193.75146771036,504246.4559686888,505299.1604696673,506351.8649706458,507404.5694716243,508457.27397260274,509509.9784735812,510562.68297455966,511615.3874755381,512668.09197651665,513720.7964774951,514773.5009784736,515826.20547945204,516878.9099804305,517931.61448140896,518984.3189823875,520037.02348336595,521089.7279843444,522142.4324853229,523195.13698630134,524247.84148727986,525300.5459882583,526353.2504892368,527405.9549902153,528458.6594911937,529511.3639921722,530564.0684931506,531616.7729941291,532669.4774951076,533722.1819960861,534774.8864970646,535827.5909980431,536880.2954990215,537933.0]\n",
       "}\n",
       "}],\n",
       "\"metainfo_list\":[]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"Jn1rs5\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ],
      "text/plain": [
       "<lets_plot.plot.core.PlotSpec at 0x35254cf70>"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot distribution of of qids using ggplot2\n",
    "ggplot(qids, aes(x=qids)) + geom_density(binwidth=10, method='histodot') + ggtitle(\" \") + labs(x=\"Question ID\", y=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat question1 and question2 into a single string\n",
    "questions = df['question1'].astype(str) + \" \" + df['question2'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = questions.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get min, max, mean, and standard deviation of a list of numbers\n",
    "def min_max_mean_std(numbers):\n",
    "    mean = sum(numbers) / len(numbers)\n",
    "    std = (sum([(x - mean) ** 2 for x in numbers]) / len(numbers)) ** 0.5\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.6450963417349 55.00734920633935\n"
     ]
    }
   ],
   "source": [
    "# call function on questions list\n",
    "mean, std = min_max_mean_std(questions)\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1319, 120.6450963417349, 55.00734920633935)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum(questions), max(questions), mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "   <div id=\"TnPbmp\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"data\":{\n",
       "},\n",
       "\"mapping\":{\n",
       "\"x\":\"x\"\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"ggtitle\":{\n",
       "\"text\":\" \"\n",
       "},\n",
       "\"theme\":{\n",
       "\"name\":\"classic\",\n",
       "\"flavor\":\"high_contrast_dark\"\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[{\n",
       "\"name\":\"Question Length\",\n",
       "\"aesthetic\":\"x\"\n",
       "},{\n",
       "\"name\":\"Count\",\n",
       "\"aesthetic\":\"y\"\n",
       "}],\n",
       "\"layers\":[{\n",
       "\"geom\":\"histogram\",\n",
       "\"mapping\":{\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"bins\":100.0,\n",
       "\"fill\":\"white\",\n",
       "\"data\":{\n",
       "\"..count..\":[2.0,13.0,920.0,8142.0,22829.0,42172.0,58809.0,55477.0,46665.0,36233.0,29694.0,21131.0,17477.0,15191.0,11139.0,8878.0,7642.0,5167.0,4393.0,3111.0,2281.0,1922.0,1474.0,674.0,570.0,484.0,396.0,272.0,237.0,174.0,167.0,147.0,122.0,73.0,52.0,37.0,16.0,14.0,16.0,12.0,11.0,2.0,9.0,1.0,4.0,2.0,1.0,1.0,1.0,0.0,3.0,3.0,1.0,1.0,0.0,0.0,1.0,1.0,2.0,0.0,0.0,2.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,3.0,1.0,9.0,1.0,1.0],\n",
       "\"x\":[3.465909999999999,16.77973,30.09355,43.40737,56.72119,70.03500999999999,83.34882999999999,96.66265,109.97646999999999,123.29028999999998,136.60411,149.91793,163.23175,176.54557,189.85939000000002,203.17321,216.48703,229.80085,243.11467,256.42849,269.74231,283.05613,296.36995,309.68377,322.99759,336.31141,349.62523,362.93905,376.25287000000003,389.56669,402.88051,416.19433,429.50815,442.82197,456.13579,469.44961,482.76342999999997,496.07725,509.39107,522.70489,536.0187099999999,549.33253,562.64635,575.96017,589.27399,602.58781,615.90163,629.21545,642.52927,655.84309,669.15691,682.47073,695.78455,709.09837,722.41219,735.72601,749.03983,762.35365,775.66747,788.98129,802.29511,815.60893,828.92275,842.23657,855.55039,868.86421,882.17803,895.49185,908.80567,922.11949,935.43331,948.74713,962.0609499999999,975.37477,988.68859,1002.0024099999999,1015.31623,1028.63005,1041.9438699999998,1055.25769,1068.5715099999998,1081.8853299999998,1095.19915,1108.5129699999998,1121.8267899999998,1135.14061,1148.4544299999998,1161.7682499999999,1175.08207,1188.3958899999998,1201.7097099999999,1215.02353,1228.3373499999998,1241.6511699999999,1254.96499,1268.2788099999998,1281.5926299999999,1294.90645,1308.2202699999998,1321.5340899999999]\n",
       "}\n",
       "}],\n",
       "\"metainfo_list\":[]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"TnPbmp\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ],
      "text/plain": [
       "<lets_plot.plot.core.PlotSpec at 0x39af76af0>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot distribution of questions using ggplot2\n",
    "ggplot(questions, aes(x=questions)) + \\\n",
    "    geom_histogram(bins = 100, fill = 'white') +\\\n",
    "          ggtitle(\" \") + labs(x=\"Question Length\", y=\"Count\") + \\\n",
    "          theme_classic() + \\\n",
    "            flavor_high_contrast_dark() \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word count for each question\n",
    "questions = df['question1'].astype(str) + \" \" + df['question2'].astype(str).tolist()\n",
    "\n",
    "# split questions into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = questions.apply(lambda x: x.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = questions.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = min_max_mean_std(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 270, 22.124200450171905, 10.074891656619457)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(questions), max(questions), mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "   <div id=\"q9orE1\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"data\":{\n",
       "},\n",
       "\"mapping\":{\n",
       "\"x\":\"x\"\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"ggtitle\":{\n",
       "\"text\":\" \"\n",
       "},\n",
       "\"theme\":{\n",
       "\"name\":\"classic\",\n",
       "\"flavor\":\"high_contrast_dark\"\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[{\n",
       "\"name\":\"Question Word Length\",\n",
       "\"aesthetic\":\"x\"\n",
       "},{\n",
       "\"name\":\"Count\",\n",
       "\"aesthetic\":\"y\"\n",
       "}],\n",
       "\"layers\":[{\n",
       "\"geom\":\"histogram\",\n",
       "\"mapping\":{\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"bins\":100.0,\n",
       "\"fill\":\"white\",\n",
       "\"data\":{\n",
       "\"..count..\":[3.0,18.0,5528.0,11487.0,39398.0,69725.0,72230.0,40311.0,45339.0,30901.0,24648.0,12128.0,14016.0,10863.0,5441.0,6554.0,4563.0,3016.0,1525.0,1763.0,1206.0,648.0,716.0,526.0,404.0,204.0,220.0,201.0,107.0,131.0,120.0,97.0,55.0,53.0,33.0,17.0,17.0,14.0,9.0,5.0,9.0,1.0,3.0,0.0,1.0,2.0,2.0,2.0,3.0,1.0,0.0,2.0,1.0,0.0,0.0,2.0,1.0,2.0,0.0,1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,4.0,1.0,3.0,2.0,3.0,1.0],\n",
       "\"x\":[1.48276,4.20028,6.9178,9.63532,12.35284,15.07036,17.787879999999998,20.505399999999998,23.22292,25.94044,28.65796,31.37548,34.092999999999996,36.81052,39.52804,42.24556,44.96308,47.6806,50.39812,53.11564,55.83316,58.55068,61.2682,63.98572,66.70324,69.42076,72.13828,74.8558,77.57332,80.29084,83.00836,85.72588,88.4434,91.16091999999999,93.87844,96.59595999999999,99.31348,102.03099999999999,104.74852,107.46603999999999,110.18356,112.90108,115.6186,118.33612,121.05364,123.77116,126.48868,129.2062,131.92372,134.64124,137.35876000000002,140.07628,142.7938,145.51132,148.22884000000002,150.94636,153.66388,156.3814,159.09892000000002,161.81644,164.53396,167.25148000000002,169.96900000000002,172.68652,175.40404,178.12156000000002,180.83908,183.5566,186.27412,188.99164000000002,191.70916,194.42668,197.1442,199.86172000000002,202.57924,205.29676,208.01428,210.73180000000002,213.44932,216.16684,218.88436000000002,221.60188,224.3194,227.03692,229.75444000000002,232.47196,235.18948,237.907,240.62452000000002,243.34204,246.05956,248.77708,251.49460000000002,254.21212,256.92964,259.64716,262.36467999999996,265.0822,267.79972,270.51723999999996]\n",
       "}\n",
       "}],\n",
       "\"metainfo_list\":[]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"q9orE1\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ],
      "text/plain": [
       "<lets_plot.plot.core.PlotSpec at 0x29dfd3880>"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot distribution of questions using ggplot2\n",
    "ggplot(questions, aes(x=questions)) + \\\n",
    "    geom_histogram(bins = 100, fill = 'white') +\\\n",
    "          ggtitle(\" \") + labs(x=\"Question Word Length\", y=\"Count\") + \\\n",
    "          theme_classic() + \\\n",
    "            flavor_high_contrast_dark()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, I will drop those questions that have 99 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove id and qid1 and qid2\n",
    "df.drop(['id', 'qid1', 'qid2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  word_count  \n",
       "0  What is the step by step guide to invest in sh...             0          26  \n",
       "1  What would happen if the Indian government sto...             0          21  \n",
       "2  How can Internet speed be increased by hacking...             0          24  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0          20  \n",
       "4            Which fish would survive in salt water?             0          20  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the missing values with empty strings\n",
    "df = df.fillna(' ')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "- Tokenization\n",
    "- Stopwords cleaning\n",
    "- Removing punctuation\n",
    "- Normalizing\n",
    "- Stemming"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #regular expression\n",
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "import string\n",
    "string.punctuation\n",
    "\n",
    "def remove_punct(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['q1_clean'] = df['question1'].apply(lambda x: remove_punct(x))\n",
    "df['q2_clean'] = df['question2'].apply(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['question1', 'question2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Alpha Numeric\n",
    "def remove_alphanumeric(text):\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function to data frame\n",
    "df['q1_clean'] = df['q1_clean'].apply(lambda x: remove_alphanumeric(x))\n",
    "df['q2_clean'] = df['q2_clean'].apply(lambda x: remove_alphanumeric(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text.split() if word.lower() not in (stop)]\n",
    "    return \" \".join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from questions\n",
    "df['q1_clean'] = df['q1_clean'].apply(lambda x: remove_stopwords(x))\n",
    "df['q2_clean'] = df['q2_clean'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted spaces and convert to lower case\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "# define class to remove unwanted spaces and convert to lower case\n",
    "class CleanText(object):\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        \n",
    "    def clean(self):\n",
    "        # remove unwanted spaces and convert to lower case\n",
    "        self.text = self.text.lower()\n",
    "        self.text = self.text.strip()\n",
    "        return self.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call class to remove unwanted spaces and convert to lower case for q1_clean and q2_clean\n",
    "df['q1_clean'] = df['q1_clean'].apply(lambda x: CleanText(x).clean())\n",
    "df['q2_clean'] = df['q2_clean'].apply(lambda x: CleanText(x).clean())\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A = deepcopy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine q1_clean and q2_clean into a single column called \"combined\" using string concatenation\n",
    "df_A['combined'] = df_A['q1_clean'].astype(str) +' ' + df_A['q2_clean'].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop q1_clean and q2_clean\n",
    "\n",
    "df_A.drop(['q1_clean', 'q2_clean'], axis=1, inplace=True)\n",
    "df_A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.to_csv('df_A.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- word count\n",
    "- number of the same words in both questions\n",
    "- ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with target\n",
    "X = pd.DataFrame(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the length of questions and apply to X df\n",
    "X['q1_len'] = df['q1_clean'].apply(lambda x: len(x))\n",
    "X['q2_len'] = df['q2_clean'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate weight of each word in corpus\n",
    "def get_weight(count, eps=10000, min_count=2):\n",
    "    return 0 if count < min_count else 1 / (count + eps)\n",
    "\n",
    "# join all questions together\n",
    "pairs_qs = df['q1_clean'].str.split().astype(str) + df['q2_clean'].str.split().astype(str) \n",
    "words = (\" \".join(pairs_qs)).lower().split()\n",
    "counts = Counter(words)\n",
    "weights = {word: get_weight(count) for word, count in counts.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['word_count'] = pairs_qs.apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of unique words in each question\n",
    "def unique_words(text):\n",
    "    doc = nlp(text)\n",
    "    unique_words = set([token.text for token in doc if token.is_stop != True and token.is_punct != True])\n",
    "    return len(unique_words)\n",
    "\n",
    "# find common words in each question\n",
    "def common_words(text):\n",
    "    doc = nlp(text)\n",
    "    common_words = set([token.text for token in doc if token.is_stop == True and token.is_punct == True])\n",
    "    return len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stops = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "def word_shares(row):\n",
    "    q1_list = str(row['q1_clean']).lower().split()\n",
    "    q1 = set(q1_list)\n",
    "    q1words = q1.difference(stops)\n",
    "    if len(q1words) == 0:\n",
    "        return '0:0:0:0:0:0:0:0:0'\n",
    "\n",
    "    q2_list = str(row['q2_clean']).lower().split()\n",
    "    q2 = set(q2_list)\n",
    "    q2words = q2.difference(stops)\n",
    "    if len(q2words) == 0:\n",
    "        return '0:0:0:0:0:0:0:0:0'\n",
    "\n",
    "    words_hamming = sum(1 for i in zip(q1_list, q2_list) if i[0]==i[1])/max(len(q1_list), len(q2_list))\n",
    "\n",
    "    q1stops = q1.intersection(stops)\n",
    "    q2stops = q2.intersection(stops)\n",
    "\n",
    "    q1_2gram = set([i for i in zip(q1_list, q1_list[1:])])\n",
    "    q2_2gram = set([i for i in zip(q2_list, q2_list[1:])])\n",
    "\n",
    "    shared_2gram = q1_2gram.intersection(q2_2gram)\n",
    "\n",
    "    shared_words = q1words.intersection(q2words)\n",
    "    shared_weights = [weights.get(w, 0) for w in shared_words]\n",
    "    q1_weights = [weights.get(w, 0) for w in q1words]\n",
    "    q2_weights = [weights.get(w, 0) for w in q2words]\n",
    "    total_weights = q1_weights + q1_weights\n",
    "\n",
    "    R1 = np.sum(shared_weights) / np.sum(total_weights) #tfidf share\n",
    "    R2 = len(shared_words) / (len(q1words) + len(q2words) - len(shared_words)) #count share\n",
    "    R31 = len(q1stops) / len(q1words) #stops in q1\n",
    "    R32 = len(q2stops) / len(q2words) #stops in q2\n",
    "    Rcosine_denominator = (np.sqrt(np.dot(q1_weights,q1_weights))*np.sqrt(np.dot(q2_weights,q2_weights)))\n",
    "    Rcosine = np.dot(shared_weights, shared_weights)/Rcosine_denominator\n",
    "    if len(q1_2gram) + len(q2_2gram) == 0:\n",
    "        R2gram = 0\n",
    "    else:\n",
    "        R2gram = len(shared_2gram) / (len(q1_2gram) + len(q2_2gram))\n",
    "    \n",
    "    fuzzy_match = fuzz.token_sort_ratio(q1_list, q2_list)\n",
    "    \n",
    "    return '{}:{}:{}:{}:{}:{}:{}:{}:{}'.format(R1, R2, len(shared_words), R31, R32, R2gram, \n",
    "                                                  Rcosine, words_hamming, fuzzy_match)\n",
    "\n",
    "X['word_shares'] = df.apply(word_shares, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['word_match']       = X['word_shares'].apply(lambda x: float(x.split(':')[0]))\n",
    "X['tfidf_word_match'] = X['word_shares'].apply(lambda x: float(x.split(':')[1]))\n",
    "X['shared_count']     = X['word_shares'].apply(lambda x: float(x.split(':')[2]))\n",
    "\n",
    "X['stops1_ratio']     = X['word_shares'].apply(lambda x: float(x.split(':')[3]))\n",
    "X['stops2_ratio']     = X['word_shares'].apply(lambda x: float(x.split(':')[4]))\n",
    "X['shared_2gram']     = X['word_shares'].apply(lambda x: float(x.split(':')[5]))\n",
    "X['cosine']           = X['word_shares'].apply(lambda x: float(x.split(':')[6]))\n",
    "X['words_hamming']    = X['word_shares'].apply(lambda x: float(x.split(':')[7]))\n",
    "X['fuzzy_match']    = X['word_shares'].apply(lambda x: float(x.split(':')[8]))\n",
    "\n",
    "\n",
    "X['len_word_q1'] = df['q1_clean'].apply(lambda x: len(str(x).split()))\n",
    "X['len_word_q2'] = df['q2_clean'].apply(lambda x: len(str(x).split()))\n",
    "X['diff_len_word'] = X['len_word_q1'] - X['len_word_q2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop word_shares column\n",
    "X.drop(['word_shares'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique values in cosine column\n",
    "X['cosine'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['cosine'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['word_match'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['word_match'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "X.to_csv('clean_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first 10000 rows from df sample data using iloc\n",
    "X = df.iloc[:100000]\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "Different modeling techniques can be used:\n",
    "\n",
    "- logistic regression\n",
    "- XGBoost\n",
    "- LSTMs\n",
    "- etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# import standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import stratified k fold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# import logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# import pipeline\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['is_duplicate']\n",
    "X = X.drop(['is_duplicate', 'stops1_ratio', 'stops2_ratio', 'word_count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test using 80:20 ratio using iloc\n",
    "y_train = y.iloc[:int(y.shape[0]*0.8)]\n",
    "y_test = y.iloc[int(y.shape[0]*0.8):]\n",
    "X_train = X.iloc[:int(X.shape[0]*0.8)]\n",
    "X_test = X.iloc[int(X.shape[0]*0.8):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_test.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Test different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'accuracy'\n",
    "kfold = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline without scaling\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "#evaluate each model in turn with cross validation\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    results.append(accuracy_score(y_test, model.predict(X_test)))\n",
    "    names.append(name)\n",
    "    msg = f'{name}: {results}'\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb classifier with learning rate 0.01\n",
    "Xgb = xgb.XGBClassifier()\n",
    "Xgb.fit(X_train, y_train)\n",
    "y_pred = Xgb.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for best hyperparameters for XGBoost\n",
    "def grid_search(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Grid search for best hyperparameters for XGBoost\n",
    "    \"\"\"\n",
    "    # import XGBoost\n",
    "    from xgboost import XGBClassifier\n",
    "    # import GridSearchCV\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    # import RandomizedSearchCV\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "    # define XGBoost parameters\n",
    "    xgb_params = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'gamma': [0.5, 1, 1.5, 2],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'reg_alpha': [1e-5, 1e-4, 1e-3],\n",
    "        'reg_lambda': [1e-5, 1e-4, 1e-3],\n",
    "        'scale_pos_weight': [1, 3, 5],\n",
    "        'objective': ['binary:logistic', 'multi:softmax'],\n",
    "        'nthread': [4],\n",
    "        'seed': [42]\n",
    "    }\n",
    "    # define XGBoost grid search\n",
    "    xgb_grid = GridSearchCV(XGBClassifier(), xgb_params, cv=2, n_jobs=-1, verbose=1)\n",
    "    # fit XGBoost grid search\n",
    "    xgb_grid.fit(X_train, y_train)\n",
    "    # print best XGBoost hyperparameters\n",
    "    print('Best XGBoost hyperparameters: ', xgb_grid.best_params_)\n",
    "    # print best XGBoost score\n",
    "    print('Best XGBoost score: ', xgb_grid.best_score_)\n",
    "    # predict on test set\n",
    "    y_pred = xgb_grid.predict(X_test)\n",
    "    # print classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    # print confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=120,batch_size=34, verbose=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear session to avoid clutter from old models / layers.\n",
    "from keras import backend as K \n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Net Using RAW Data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_A.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take sample of first 10000 rows from df sample data using iloc\n",
    "sample = df.iloc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample['combined']\n",
    "y = sample['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y.iloc[:int(y.shape[0]*0.8)]\n",
    "y_test = y.iloc[int(y.shape[0]*0.8):]\n",
    "X_train = X.iloc[:int(X.shape[0]*0.8)]\n",
    "X_test = X.iloc[int(X.shape[0]*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=3000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "embedding_dim = 50\n",
    "maxlen = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    verbose=False,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
