{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First Network**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 8s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Seperate data into train and test\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "# check a sample image\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`In our train sample, we can see that we have 60,000 images with the size 28x28 pixels. We have 60,000 labels labeling the images from 0 to 9.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now going to build our first network which will predict what number is in the picture:\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(784, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(784, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "network.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Before we can feed our data into our newly created model, we will need to reshape our input into a format \\\n",
    "    that the model can read. The original shape of our input was [60000, 28, 28] \\\n",
    "        which essentially represents 60,000 images with the pixel height and width of 28x28. \\\n",
    "            We will reshape it, so that we have all pixels for each image in one row of a 2D array. \\\n",
    "                We can think about this as a dataset with 60,000 rows and 28*28 columns.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`We also have to make sure our network thinks it is a categorical problem because numbers from 0 to 9 \\\n",
    "can be interpreted as regression as well. So we will encode our target as categories:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0226 - accuracy: 0.9923\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0197 - accuracy: 0.9934\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0154 - accuracy: 0.9951\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0188 - accuracy: 0.9939\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0115 - accuracy: 0.9964\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0159 - accuracy: 0.9949\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0109 - accuracy: 0.9965\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0095 - accuracy: 0.9969\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0126 - accuracy: 0.9955\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0086 - accuracy: 0.9974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x178fa6b80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we are now ready to train our NN! To do this, we will call the fit function and pass in the required parameters:\n",
    "network.fit(train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0926 - accuracy: 0.9822\n",
      "test_acc: 0.982200026512146 test_loss 0.09255945682525635\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc, 'test_loss', test_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have just taken the first step on our deep learning journey. <br>\n",
    "We have seen that creating a network and using it as a black box is not all that complex. <br>\n",
    "However, in order to maximize the added value of using deep learning networks, it's fundamental to also understand what is going on during the different steps.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
